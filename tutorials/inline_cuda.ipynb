{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumm Inline CUDA Tutorial\n",
    "This Tutorial will show how to write cuda kernels in a simple way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], device='cuda:0')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cumm.inliner import NVRTCInlineBuilder\n",
    "from cumm.common import TensorViewNVRTC\n",
    "from cumm import tensorview as tv\n",
    "\n",
    "import torch \n",
    "import numpy as np \n",
    "\n",
    "# we need to init cuda first\n",
    "torch.zeros([1]).cuda()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Kernel \n",
    "\n",
    "To write any inliner-based code, you need to specify dependency first.\n",
    "cumm provides some default dependency that includes ```tensorview/core```:\n",
    "\n",
    "```Python\n",
    "from cumm.common import TensorViewNVRTC\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload_when_code_change: should only be used in GUI apps or jupyter environment\n",
    "inliner = NVRTCInlineBuilder([TensorViewNVRTC], reload_when_code_change=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capture-Based CUDA Code\n",
    "\n",
    "code in cumm.inliner don't contains inputs, all inputs are captured from local variables in current frames.\n",
    "\n",
    "When you write ```$some_var``` in inline code, cumm.inliner will locate ```some_var``` in current frame and generate code for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_var = 1\n",
    "\n",
    "inliner.kernel_1d(\"unique_name_in_a_file\", 1, 0, f\"\"\"\n",
    "tv::printf2($some_var);\n",
    "\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We support following python types to be captured:\n",
    "\n",
    "* tv.Tensor -> raw ptr or tv::TensorView\n",
    "* torch.Tensor -> raw ptr or tv::TensorView\n",
    "* int/float/bool -> int64_t/float/bool\n",
    "* np.ndarray -> tv::array, size MUST smaller than 50\n",
    "* list/tuple of int/float/bool -> tv::array, will be converted to np.ndarray, size MUST smaller than 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "some_arr = np.eye(4)\n",
    "some_ten_tv = tv.zeros([2], tv.float32, 0)\n",
    "some_ten_torch = torch.rand(5).cuda()\n",
    "# here we use a same name as previous kernel_1d but different code, the cached cuda binary will be invalid,\n",
    "# so we need to run compile again.\n",
    "# to prevent compile code in every kernel_1d, disable reload_when_code_change.\n",
    "inliner.kernel_1d(\"unique_name_in_a_file\", 1, 0, f\"\"\"\n",
    "tv::printf2($some_arr[0][0], $some_arr[1][1], $some_arr[0][2], $some_arr[3][3]);\n",
    "tv::printf2($some_ten_tv[0], $some_ten_tv[1]);\n",
    "tv::printf2($some_ten_torch[0], $some_ten_torch[1]);\n",
    "\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```$some_var``` isn't suitable for complex exprs such as ```self.some_var```, so we support another type of capture: ```$(self.complex_expr.dim(0))```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000000 1.000000 0.000000 1.000000\n",
      "0.000000 0.000000\n",
      "0.137446 0.927519\n"
     ]
    }
   ],
   "source": [
    "some_arr = np.eye(4)\n",
    "inliner.kernel_1d(\"unique_name_in_a_file\", 1, 0, f\"\"\"\n",
    "tv::printf2($(some_arr.shape[0]));\n",
    "\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D kernels or Raw Kernels\n",
    "\n",
    "When you use kernel_1d, a variable ```i``` will be reversed as a standard 1d kernel index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "some_ten = torch.rand(5000).cuda()\n",
    "inliner.kernel_1d(\"unique_name_in_a_file\", some_ten.shape[0], 0, f\"\"\"\n",
    "$some_ten[i] = 0;\n",
    "\"\"\")\n",
    "print(some_ten.mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also support standard kernel params: blocks, threads, smem size and stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "some_ten = torch.rand(5000).cuda()\n",
    "inliner.kernel_raw(\"unique_name_in_a_file\", tv.LaunchParam((1, 1, 1), (1024, 1,1), 0, 0), f\"\"\"\n",
    "for (int i = blockIdx.x * blockDim.x + threadIdx.x; \n",
    "        i < $(some_ten.shape[0]); \n",
    "        i += blockDim.x * gridDim.x) \n",
    "{{\n",
    "    $some_ten[i] = 0;\n",
    "}}\n",
    "\"\"\")\n",
    "print(some_ten.mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-World kernel examples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform Point Cloud in CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use INLINER as a global variable to avoid recompile\n",
    "\n",
    "INLINER = NVRTCInlineBuilder([], reload_when_code_change=True)\n",
    "\n",
    "def transform_pc(pc: torch.Tensor, tr: np.ndarray):\n",
    "    out_pc = pc.clone()\n",
    "    INLINER.kernel_1d(\"transform_pc\", pc.shape[0], 0, f\"\"\"\n",
    "    auto pc_ptr = $pc + i * $(pc.stride(0));\n",
    "    auto out_pc_ptr = $out_pc + i * $(out_pc.stride(0));\n",
    "    auto x = pc_ptr[0];\n",
    "    auto y = pc_ptr[1];\n",
    "    auto z = pc_ptr[2];\n",
    "    out_pc_ptr[0] = $tr[0][0] * x + $tr[0][1] * y + $tr[0][2] * z + $tr[0][3];\n",
    "    out_pc_ptr[1] = $tr[1][0] * x + $tr[1][1] * y + $tr[1][2] * z + $tr[1][3];\n",
    "    out_pc_ptr[2] = $tr[2][0] * x + $tr[2][1] * y + $tr[2][2] * z + $tr[2][3];\n",
    "    \"\"\")\n",
    "    return out_pc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
